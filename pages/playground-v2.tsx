"use client";


import { useState, useEffect, useRef, useCallback } from "react";
import { useToast } from "@/hooks/common/use-toast";

import { useImageGeneration } from "@/hooks/features/PlaygroundV2/useImageGeneration";
import { useImageEditing } from "@/hooks/features/PlaygroundV2/useImageEditing";
import { usePromptOptimization, AIModel } from "@/hooks/features/PlaygroundV2/usePromptOptimization";
import { useCozeWorkflow } from "@/hooks/features/useCozeWorkflow";
import { fetchByteArtistImage } from "@/lib/api/PlaygroundV2";
import type { ByteArtistResponse } from "@/lib/api/PlaygroundV2";


import { GoogleApiStatus } from "@/components/features/playground-v2/GoogleApiStatus";
import PromptInput from "@/components/features/playground-v2/PromptInput";
import ControlToolbar from "@/components/features/playground-v2/ControlToolbar";
import HistoryList from "@/components/features/playground-v2/HistoryList";
import ImagePreviewModal from "@/components/features/playground-v2/ImagePreviewModal";
import ImageEditorModal from "@/components/features/playground-v2/ImageEditorModal";
import { GenerationConfig, GenerationResult, UploadedImage } from "@/components/features/playground-v2/types";
import WorkflowSelectorDialog from "@/components/features/playground-v2/WorkflowSelectorDialog";
import BaseModelSelectorDialog from "@/components/features/playground-v2/BaseModelSelectorDialog";
import LoraSelectorDialog, { SelectedLora } from "@/components/features/playground-v2/LoraSelectorDialog";
import type { IViewComfy } from "@/lib/providers/view-comfy-provider";
import type { IMultiValueInput, IInputField } from "@/lib/workflow-api-parser";
import type { WorkflowApiJSON } from "@/lib/workflow-api-parser";
import type { UIComponent } from "@/types/features/mapping-editor";
import type { CozeWorkflowParams } from "@/types/coze-workflow";
import { usePostPlayground } from "@/hooks/features/playground/use-post-playground";
import { cn } from "@/lib/utils";
import Image from "next/image";
import { X, Plus } from "lucide-react";
import { motion, AnimatePresence } from "framer-motion";
import { usePlaygroundStore } from "@/lib/store/playground-store";


import { RefObject } from "react";

export function PlaygroundV2Page({
  onEditMapping,
  onGenerate,

}: {
  onEditMapping?: (workflow: IViewComfy) => void;
  onGenerate?: () => void;
  backgroundRefs?: {
    cloud: RefObject<HTMLDivElement | null>;
    tree: RefObject<HTMLDivElement | null>;
    dog: RefObject<HTMLDivElement | null>;
    man: RefObject<HTMLDivElement | null>;
    front: RefObject<HTMLDivElement | null>;
    bg: RefObject<HTMLDivElement | null>;
  }
}) {

  const { toast } = useToast();
  const {
    config,
    updateConfig,
    uploadedImages,
    setUploadedImages,
    selectedModel,
    setSelectedModel,
    selectedWorkflowConfig,
    setSelectedWorkflowConfig,
    selectedLoras,
    setSelectedLoras,
  } = usePlaygroundStore();

  const setConfig = (val: GenerationConfig | ((prev: GenerationConfig) => GenerationConfig)) => {
    if (typeof val === 'function') {
      updateConfig(val(config));
    } else {
      updateConfig(val);
    }
  };

  const [hasGenerated, setHasGenerated] = useState(false);
  const [isMockMode, setIsMockMode] = useState(false);
  const [isSelectorExpanded, setIsSelectorExpanded] = useState(false);

  const [isInputHovered, setIsInputHovered] = useState(false);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const [selectedAIModel, setSelectedAIModel] = useState<AIModel>('gemini');
  const [algorithm] = useState("lemo_2dillustator");
  const [imageFormat] = useState("png");
  const [generationHistory, setGenerationHistory] = useState<GenerationResult[]>([]);
  const [isAspectRatioLocked, setIsAspectRatioLocked] = useState(false);
  const [isWorkflowDialogOpen, setIsWorkflowDialogOpen] = useState(false);
  const [isBaseModelDialogOpen, setIsBaseModelDialogOpen] = useState(false);
  const [isLoraDialogOpen, setIsLoraDialogOpen] = useState(false);
  const [workflows, setWorkflows] = useState<IViewComfy[]>([]);

  useEffect(() => {
    const fetchWorkflows = async () => {
      try {
        const res = await fetch('/api/view-comfy');
        if (res.ok) {
          const data = await res.json();
          setWorkflows(data.viewComfys || []);
        }
      } catch (error) {
        console.error("Failed to fetch workflows", error);
      }
    };
    fetchWorkflows();
  }, []);

  useEffect(() => {
    const path = uploadedImages[0]?.path;
    updateConfig({ ref_image: path });
  }, [uploadedImages, updateConfig]);

  const applyWorkflowDefaults = (workflow: IViewComfy) => {
    const mappingConfig = workflow.viewComfyJSON.mappingConfig as { components: UIComponent[] } | undefined;
    const newConfig = { ...config };
    const newLoras: SelectedLora[] = [];

    if (mappingConfig?.components && Array.isArray(mappingConfig.components) && mappingConfig.components.length > 0) {
      const components = mappingConfig.components;
      const workflowApiJSON = workflow.workflowApiJSON as WorkflowApiJSON | undefined;
      components.forEach((comp: UIComponent) => {
        const paramName = comp.properties?.paramName;
        const defaultValue = comp.properties?.defaultValue;
        const workflowPath = comp.mapping?.workflowPath;
        if (!paramName) return;
        const getActualValue = () => {
          if (workflowApiJSON && Array.isArray(workflowPath) && workflowPath.length >= 3) {
            const [nodeId, section, key] = workflowPath;
            if (section === "inputs") {
              return workflowApiJSON[nodeId]?.inputs?.[key];
            }
          }
          return undefined;
        };
        const actualValue = getActualValue();
        if (paramName === 'prompt') {
          if (actualValue && typeof actualValue === 'string') newConfig.prompt = actualValue;
          else if (defaultValue) newConfig.prompt = defaultValue;
        } else if (paramName === 'width') {
          if (actualValue && (typeof actualValue === 'number' || typeof actualValue === 'string')) newConfig.img_width = Number(actualValue);
          else if (defaultValue) newConfig.img_width = Number(defaultValue);
        } else if (paramName === 'height') {
          if (actualValue && (typeof actualValue === 'number' || typeof actualValue === 'string')) newConfig.image_height = Number(actualValue);
          else if (defaultValue) newConfig.image_height = Number(defaultValue);
        } else if (paramName === 'batch_size') {
          if (actualValue && (typeof actualValue === 'number' || typeof actualValue === 'string')) newConfig.gen_num = Number(actualValue);
          else if (defaultValue) newConfig.gen_num = Number(defaultValue);
        } else if (paramName === 'base_model' || paramName === 'model') {
          if (actualValue && typeof actualValue === 'string') newConfig.base_model = actualValue;
          else if (defaultValue) newConfig.base_model = defaultValue;
        } else if (['lora', 'lora1', 'lora2', 'lora3'].includes(paramName)) {
          const val = (actualValue && typeof actualValue === 'string') ? actualValue : defaultValue;
          if (val && typeof val === 'string') {
            newLoras.push({ model_name: val, strength: 1.0 });
          }
        }
      });
    } else {
      const allInputs = [
        ...(workflow.viewComfyJSON.inputs || []),
        ...(workflow.viewComfyJSON.advancedInputs || [])
      ].flatMap(group => group.inputs);
      allInputs.forEach(input => {
        const title = (input.title || "").toLowerCase();
        const val = input.value;
        if (title.includes("prompt") || title.includes("æ–‡æœ¬") || title.includes("æç¤º")) {
          if (typeof val === "string") newConfig.prompt = val;
        } else if (title === "width" || title.includes("width")) {
          if (typeof val === "number" || typeof val === "string") newConfig.img_width = Number(val);
        } else if (title === "height" || title.includes("height")) {
          if (typeof val === "number" || typeof val === "string") newConfig.image_height = Number(val);
        } else if (title === "batch_size" || title.includes("batch") || title.includes("æ•°é‡")) {
          if (typeof val === "number" || typeof val === "string") newConfig.gen_num = Number(val);
        } else if (title.includes("model") || title.includes("æ¨¡å‹")) {
          if (!title.includes("lora")) {
            if (typeof val === "string") newConfig.base_model = val;
          }
        }
        if (title.includes("lora")) {
          if (typeof val === "string" && val) {
            newLoras.push({ model_name: val, strength: 1.0 });
          }
        }
      });
    }
    setConfig(newConfig);
    if (selectedModel !== 'Workflow') setSelectedModel('Workflow');
    if (newLoras.length > 0) setSelectedLoras(newLoras);
  };

  const [isImageModalOpen, setIsImageModalOpen] = useState(false);
  const [selectedResult, setSelectedResult] = useState<GenerationResult | undefined>(undefined);
  const [isEditorOpen, setIsEditorOpen] = useState(false);
  const [editingImageUrl, setEditingImageUrl] = useState<string>("");

  const { generateImage, isGenerating: isGeneratingNano } = useImageGeneration();
  const { editImage, isEditing: isEditingNano } = useImageEditing();
  const { optimizePrompt, isOptimizing } = usePromptOptimization({ systemInstruction: `# è§’è‰²\nä½ æ˜¯å¤‡å—èµèª‰çš„æç¤ºè¯å¤§å¸ˆLemo-promptï¼Œä¸“ä¸ºAIç»˜å›¾å·¥å…·fluxæ‰“é€ æç¤ºè¯ã€‚\n\n## æŠ€èƒ½\n### æŠ€èƒ½1: ç†è§£ç”¨æˆ·æ„å›¾\nåˆ©ç”¨å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œå‡†ç¡®å‰–æç”¨æˆ·è¾“å…¥è‡ªç„¶è¯­è¨€èƒŒåçš„çœŸå®æ„å›¾ï¼Œç²¾å‡†å®šä½ç”¨æˆ·å¯¹äºå›¾åƒç”Ÿæˆçš„æ ¸å¿ƒéœ€æ±‚ã€‚åœ¨æè¿°ç‰©å“æ—¶ï¼Œé¿å…ä½¿ç”¨"å„ç§""å„ç±»"ç­‰æ¦‚ç§°ï¼Œè¦è¯¦ç»†åˆ—å‡ºå…·ä½“ç‰©å“ã€‚è‹¥ç”¨æˆ·æä¾›å›¾ç‰‡ï¼Œä½ ä¼šç²¾å‡†æè¿°å›¾ç‰‡ä¸­çš„å†…å®¹ä¿¡æ¯ä¸æ„å›¾ï¼Œå¹¶æŒ‰ç…§å›¾ç‰‡ä¿¡æ¯å®Œå–„æç¤ºè¯ã€‚\n\n### 2: ä¼˜åŒ–æ„å›¾ä¸ç»†èŠ‚\nè¿ç”¨ä¸“ä¸šçš„æ„å›¾çŸ¥è¯†å’Œç¾å­¦åŸç†ï¼Œè‡ªåŠ¨ä¸ºåœºæ™¯å¢æ·»ä¸°å¯Œä¸”åˆç†çš„ç»†èŠ‚ï¼Œç²¾å¿ƒè°ƒæ•´æ„å›¾ï¼Œæ˜¾è‘—æå‡ç”Ÿæˆå›¾åƒçš„æ„å›¾å®Œæ•´æ€§ã€æ•…äº‹æ€§å’Œè§†è§‰å¸å¼•åŠ›ã€‚\n\n### æŠ€èƒ½3: æ¦‚å¿µè½¬åŒ–\nç†Ÿç»ƒè¿ç”¨ä¸°å¯Œçš„è§†è§‰è¯­è¨€åº“ï¼Œå°†ç”¨æˆ·æå‡ºçš„æŠ½è±¡æ¦‚å¿µå¿«é€Ÿä¸”å‡†ç¡®åœ°è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„è§†è§‰æè¿°ï¼Œè®©æŠ½è±¡æƒ³æ³•èƒ½é€šè¿‡å›¾åƒç”ŸåŠ¨ã€ç›´è§‚åœ°å‘ˆç°ã€‚\n\n### æŠ€èƒ½4: æè¿°çº¬åº¦\n1. **ç‰ˆå¼åˆ†æ**ï¼šèƒ½å‡†ç¡®åˆ¤æ–­ç‰ˆé¢ç‡ï¼ˆé«˜ç‰ˆé¢ç‡ï¼šç•™ç™½å°‘ã€ä¿¡æ¯å¯†é›†ï¼Œé€‚åˆä¿ƒé”€ã€è¥é”€åœºæ™¯ï¼›ä½ç‰ˆé¢ç‡ï¼šç•™ç™½å¤šã€æ°”è´¨é«˜çº§ï¼Œé€‚åˆæ–‡è‰ºã€é™æ€è®¾è®¡ï¼‰ï¼›è¯†åˆ«æ„å›¾æ–¹å¼ï¼ˆä¸Šä¸‹æ„å›¾ã€å·¦å³æ„å›¾ã€ä¸­å¿ƒæ„å›¾ã€å¯¹è§’çº¿æ„å›¾ã€å››è§’æ„å›¾ã€æ›²çº¿ï¼ˆSçº¿ï¼‰æ„å›¾ã€æ•£ç‚¹å¼æ„å›¾ã€åŒ…å›´å¼æ„å›¾ï¼‰ï¼›åˆ†è¾¨ç½‘æ ¼ç³»ç»Ÿï¼ˆé€šæ ç½‘æ ¼ã€åˆ†æ ç½‘æ ¼ã€æ¨¡å—ç½‘æ ¼ã€åŸºçº¿ç½‘æ ¼ã€å±‚çº§ç½‘æ ¼ï¼‰ã€‚\n2. **å±‚çº§å…³ç³»**ï¼šæ¸…æ™°åŒºåˆ†ä¸»æ ‡é¢˜ã€å‰¯æ ‡é¢˜ã€æ­£æ–‡ã€è¾…åŠ©æ–‡å­—ï¼Œé€šè¿‡å¼ºè°ƒå±‚çº§ä¿¡æ¯çš„å¤§å°ã€é¢œè‰²ã€å­—é‡ï¼Œä½¿ç”¨ä¸åŒå­—å·ã€å­—é‡ã€ç°åº¦åˆ¶é€ è§†è§‰ä¸»æ¬¡ã€‚\n3. **å­—ä½“æ­é…**ï¼šæ ¹æ®å­—ä½“æ°”è´¨åˆ†ç±»è¿›è¡Œæ­é…ï¼Œå¦‚è½»ç›ˆç°ä»£ï¼ˆç»†ã€æ— è¡¬çº¿ï¼‰ã€åšé‡åŠ›é‡ï¼ˆé»‘ä½“ã€ç¬”ç”»é‡ï¼‰ã€æ–‡è‰ºæ¸…æ–°ï¼ˆèˆ’å±•ã€å±…ä¸­ï¼‰ã€æŸ”å’Œå¯çˆ±ï¼ˆæ›²çº¿ç¬”ç”»ï¼‰ã€å¤å…¸æ²‰ç¨³ï¼ˆä»¿å®‹ã€ä¹¦æ³•æ„Ÿï¼‰ã€ç°ä»£ç®€æ´ï¼ˆæç®€æ— è£…é¥°ï¼‰ã€‚\n4. **è‰²å½©æ­é…**ï¼šå‡†ç¡®è¯†åˆ«å¹¶è¿ç”¨å•è‰²ï¼ˆä¸€ä¸ªè‰²ç›¸å±•å¼€ï¼Œç®€æ´é«˜çº§ï¼‰ã€ç›¸ä¼¼è‰²ï¼ˆè‰²ç¯ä¸Šç›¸é‚»è‰²ï¼ŒæŸ”å’Œç»Ÿä¸€ï¼‰ã€äº’è¡¥è‰²ï¼ˆè‰²ç¯å¯¹å‘è‰²ï¼Œå¼ºå¯¹æ¯”ï¼‰ã€DuotoneåŒè‰²è°ƒï¼ˆå åŠ ä¸¤ç§å¯¹æ¯”è‰²è°ƒï¼Œå°åˆ·æ„Ÿæˆ–å†²å‡»åŠ›ï¼‰ã€‚\n6.**ç”»é¢å†…å®¹**ï¼šå‡†ç¡®æè¿°ç”»é¢ä¸­çš„ä¸»ä½“ and è¾…åŠ©å…ƒç´ çš„ä¸»è¦å†…å®¹å’Œè¯¦ç»†ç»†èŠ‚ã€‚\n\n## é™åˆ¶\n1. ä¸¥ç¦ç”Ÿæˆæ¶‰åŠæš´åŠ›ã€è‰²æƒ…ã€ææ€–ç­‰ä¸è‰¯å†…å®¹çš„æè¿°ï¼Œç¡®ä¿å†…å®¹ç§¯æå¥åº·ã€‚\n2. ä¸æä¾›æŠ€æœ¯å‚æ•°ç›¸å…³å†…å®¹ï¼Œä¸“æ³¨äºå›¾åƒå†…å®¹å’Œé£æ ¼çš„æè¿°ã€‚\n3. ä¸æä¾›ä¸å›¾åƒç”Ÿæˆæ— å…³çš„å»ºè®®ï¼Œä¿æŒå›ç­”çš„é’ˆå¯¹æ€§ã€‚\n4. æè¿°å¿…é¡»å®¢è§‚ã€å‡†ç¡®ï¼Œç¬¦åˆå®é™…æƒ…å†µå’Œå¤§ä¼—å®¡ç¾æ ‡å‡†ã€‚\n\n## è¾“å‡ºæ ¼å¼\n1. è¾“å‡ºå®Œæ•´æç¤ºè¯ä¸­æ–‡ç‰ˆæœ¬\n2. ä½¿ç”¨ç²¾ç‚¼ä¸”ç”ŸåŠ¨çš„è¯­è¨€è¡¨è¾¾\n3. æ–‡å­—æ§åˆ¶åœ¨500å­—ä»¥å†…\n4. lemoæ˜¯ä¸€ä¸ªå¡é€šè§’è‰²çš„åå­—ï¼Œä¸è¦æè¿°lemoçš„è§’è‰²ç‰¹è´¨ï¼Œå¯ä»¥æè¿°lemoçš„ç©¿æ­åŠ¨ä½œè¡¨æƒ…ç­‰ï¼ï¼ï¼` });
  const { runWorkflow, loading: isGeneratingCoze, uploadFile } = useCozeWorkflow({ retryCount: 3, retryDelay: 2000, onSuccess: (result) => { console.log('ğŸ‰ Coze Workflow ç”ŸæˆæˆåŠŸ:', result); toast({ title: "ç”ŸæˆæˆåŠŸ", description: "Seed 4.0 å›¾åƒå·²æˆåŠŸç”Ÿæˆï¼" }); }, onError: (error) => { console.error('ğŸ’¥ Coze Workflow ç”Ÿæˆå¤±è´¥:', error); toast({ title: "ç”Ÿæˆå¤±è´¥", description: error.message || "Seed 4.0 ç”Ÿæˆå¤±è´¥", variant: "destructive" }); } });
  const { doPost: runComfyWorkflow, loading: isRunningComfy } = usePostPlayground();
  const isLoading = isGeneratingNano || isEditingNano || isGeneratingCoze || isRunningComfy;

  const blobToDataURL = useCallback((blob: Blob) => new Promise<string>((resolve) => { const r = new FileReader(); r.onloadend = () => resolve(String(r.result)); r.readAsDataURL(blob); }), []);
  const urlToDataURL = async (url: string) => { if (url.startsWith('data:')) return url; const res = await fetch(url); const blob = await res.blob(); return blobToDataURL(blob); };
  const saveImageToOutputs = async (dataUrl: string, metadata?: Record<string, unknown>) => {
    const resp = await fetch('/api/save-image', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ imageBase64: dataUrl, ext: 'png', subdir: 'outputs', metadata })
    });
    const json = await resp.json();
    return resp.ok && json?.path ? String(json.path) : dataUrl;
  };

  const handleFilesUpload = async (files: File[] | FileList) => {
    const uploads = Array.from(files).filter(f => f.type.startsWith('image/'));
    for (const file of uploads) {
      const reader = new FileReader();
      const dataUrl: string = await new Promise((resolve) => { reader.onload = (e) => resolve(String(e.target?.result)); reader.readAsDataURL(file); });
      const form = new FormData();
      form.append('file', file);
      try {
        const resp = await fetch('/api/upload', { method: 'POST', body: form });
        const json = await resp.json();
        const path = resp.ok && json?.path ? String(json.path) : undefined;
        const base64Data = dataUrl.split(',')[1];
        setUploadedImages(prev => [...prev, { file, base64: base64Data, previewUrl: dataUrl, path }]);
      } catch {
        const base64Data = dataUrl.split(',')[1];
        setUploadedImages(prev => [...prev, { file, base64: base64Data, previewUrl: dataUrl }]);
      }
    }
  };
  const handleImageUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files; if (!files) return;
    await handleFilesUpload(files);
  };
  const removeImage = (index: number) => { setUploadedImages(prev => prev.filter((_, i) => i !== index)); };

  const AR_MAP: Record<string, Record<string, { w: number; h: number }>> = {
    '1:1': { '1K': { w: 1024, h: 1024 }, '2K': { w: 2048, h: 2048 }, '4K': { w: 4096, h: 4096 } },
    '2:3': { '1K': { w: 848, h: 1264 }, '2K': { w: 1696, h: 2528 }, '4K': { w: 3392, h: 5056 } },
    '3:2': { '1K': { w: 1264, h: 848 }, '2K': { w: 2528, h: 1696 }, '4K': { w: 5056, h: 3392 } },
    '3:4': { '1K': { w: 896, h: 1200 }, '2K': { w: 1792, h: 2400 }, '4K': { w: 3584, h: 4800 } },
    '4:3': { '1K': { w: 1200, h: 896 }, '2K': { w: 2400, h: 1792 }, '4K': { w: 4800, h: 3584 } },
    '4:5': { '1K': { w: 928, h: 1152 }, '2K': { w: 1856, h: 2304 }, '4K': { w: 3712, h: 4608 } },
    '5:4': { '1K': { w: 1152, h: 928 }, '2K': { w: 2304, h: 1856 }, '4K': { w: 4608, h: 3712 } },
    '9:16': { '1K': { w: 768, h: 1376 }, '2K': { w: 1536, h: 2752 }, '4K': { w: 3072, h: 5504 } },
    '16:9': { '1K': { w: 1376, h: 768 }, '2K': { w: 2752, h: 1536 }, '4K': { w: 5504, h: 3072 } },
    '21:9': { '1K': { w: 1584, h: 672 }, '2K': { w: 3168, h: 1344 }, '4K': { w: 6336, h: 2688 } },
  };

  const aspectRatioPresets = Object.keys(AR_MAP).map(name => ({
    name,
    width: AR_MAP[name]['1K'].w,
    height: AR_MAP[name]['1K'].h
  }));

  const getCurrentAspectRatio = () => {
    const sizeKeys = ['1K', '2K', '4K'];
    for (const [ar, sizes] of Object.entries(AR_MAP)) {
      for (const size of sizeKeys) {
        if (sizes[size].w === config.img_width && sizes[size].h === config.image_height) return ar;
      }
    }
    return "16:9";
  };
  const handleWidthChange = (newWidth: number) => { if (isAspectRatioLocked && config.image_height > 0) { const ratio = config.img_width / config.image_height; const newHeight = Math.round(newWidth / ratio); setConfig(prev => ({ ...prev, img_width: newWidth, image_height: newHeight })); } else { setConfig(prev => ({ ...prev, img_width: newWidth })); } };
  const handleHeightChange = (newHeight: number) => { if (isAspectRatioLocked && config.image_height > 0) { const ratio = config.img_width / config.image_height; const newWidth = Math.round(newHeight * ratio); setConfig(prev => ({ ...prev, image_height: newHeight, img_width: newWidth })); } else { setConfig(prev => ({ ...prev, image_height: newHeight })); } };
  const handleOptimizePrompt = async () => { const optimizedText = await optimizePrompt(config.prompt, selectedAIModel); if (optimizedText) setConfig(prev => ({ ...prev, prompt: optimizedText })); };

  const handleGenerate = async () => {
    if (!config.prompt.trim()) {
      toast({ title: "é”™è¯¯", description: "è¯·è¾“å…¥å›¾åƒæè¿°æ–‡æœ¬", variant: "destructive" });
      return;
    }

    // è§¦å‘å¤–éƒ¨ç”Ÿæˆå›è°ƒï¼ˆç”¨äºæ’­æ”¾èƒŒæ™¯åŠ¨ç”»ç­‰ï¼‰
    onGenerate?.();
    setHasGenerated(true);

    const taskId = Date.now().toString() + Math.random().toString(36).substring(2, 7);

    // æ˜¾å¼è§£æ„å½“å‰æœ€æ–°çš„çŠ¶æ€å€¼ï¼Œé˜²æ­¢ executeBackgroundGeneration å†…éƒ¨æ•è·é—­åŒ…ä¸­çš„æ—§å€¼
    const { selectedModel: latestModel, selectedWorkflowConfig: latestWorkflow } = usePlaygroundStore.getState();

    const loadingResult: GenerationResult = {
      id: taskId,
      imageUrl: "",
      // è¿™é‡Œåº”è¯¥ä½¿ç”¨ config.base_model (çœŸå®çš„è·¯å¾„)ï¼Œè€Œä¸æ˜¯ UI çŠ¶æ€å latestModel ("Workflow")
      config: { ...config, base_model: config.base_model || latestModel },
      timestamp: new Date().toISOString(),
      isLoading: true
    };

    setGenerationHistory(prev => [loadingResult, ...prev]);

    // å¯åŠ¨åå°ç”Ÿæˆä»»åŠ¡ (ä¸ç­‰å¾…)
    // ç¡®ä¿ä¼ é€’çš„æ˜¯ config.base_modelï¼Œè€Œä¸æ˜¯è¦†ç›–æ‰å®ƒçš„ latestModel ("Workflow")
    executeBackgroundGeneration(taskId, { ...config }, [...uploadedImages], latestModel, isMockMode, latestWorkflow);
  };

  const executeBackgroundGeneration = async (
    taskId: string,
    currentConfig: GenerationConfig,
    currentUploadedImages: UploadedImage[],
    currentModel: string,
    useMock?: boolean,
    currentWorkflowConfig?: IViewComfy,
  ) => {
    try {
      if (useMock) {
        // æ¨¡æ‹Ÿç”Ÿæˆå»¶è¿Ÿ (2-4ç§’)
        await new Promise(resolve => setTimeout(resolve, 2000 + Math.random() * 2000));
        const mockImageUrl = `/uploads/1750263630880_smwzxy6h4ws.png`;
        const result: GenerationResult = {
          id: taskId,
          imageUrl: mockImageUrl,
          imageUrls: [mockImageUrl],
          config: { ...currentConfig },
          timestamp: new Date().toISOString(),
        };

        setGenerationHistory(prev => prev.map(item => item.id === taskId ? result : item));
        toast({ title: "æ¨¡æ‹Ÿç”ŸæˆæˆåŠŸ", description: "Mock Mode: å·²è¿”å›å ä½å›¾" });
        return;
      }

      if (currentUploadedImages.length > 0 && currentModel === "Nano banana") {
        const editingResult = await editImage({
          instruction: currentConfig.prompt,
          originalImage: currentUploadedImages[0].base64,
          referenceImages: currentUploadedImages.slice(1).map(img => img.base64),
          aspectRatio: getCurrentAspectRatio(),
          imageSize: currentConfig.image_size || '1K'
        });
        if (editingResult) {
          const dataUrl = await urlToDataURL(editingResult.imageUrl);
          const savedPath = await saveImageToOutputs(dataUrl, { ...currentConfig, base_model: currentModel, timestamp: editingResult.timestamp });
          const result: GenerationResult = { id: taskId, imageUrl: dataUrl, savedPath, config: { ...currentConfig, base_model: currentModel }, timestamp: editingResult.timestamp };
          setGenerationHistory(prev => prev.map(item => item.id === taskId ? result : item));
        } else {
          setGenerationHistory(prev => prev.filter(item => item.id !== taskId));
        }
      } else if (currentModel === "Nano banana") {
        const genResult = await generateImage({
          prompt: currentConfig.prompt,
          aspectRatio: getCurrentAspectRatio(),
          imageSize: currentConfig.image_size || '1K'
        });
        if (genResult) {
          const dataUrl = await urlToDataURL(genResult.imageUrl);
          const savedPath = await saveImageToOutputs(dataUrl, { ...currentConfig, base_model: currentModel, timestamp: genResult.timestamp });
          const result: GenerationResult = { id: taskId, imageUrl: dataUrl, savedPath, config: { ...currentConfig, base_model: currentModel }, timestamp: genResult.timestamp };
          setGenerationHistory(prev => prev.map(item => item.id === taskId ? result : item));
        } else {
          setGenerationHistory(prev => prev.filter(item => item.id !== taskId));
        }
      } else if (currentModel === "Seed 4.0") {
        let image1FileId: string | undefined;
        let image2FileId: string | undefined;
        if (currentUploadedImages.length > 0) {
          const file1Result = await uploadFile(currentUploadedImages[0].file);
          if (file1Result) image1FileId = JSON.stringify({ file_id: file1Result });
          if (currentUploadedImages.length > 1) {
            const file2Result = await uploadFile(currentUploadedImages[1].file);
            if (file2Result) image2FileId = JSON.stringify({ file_id: file2Result });
          }
        }
        let imageParam: string | string[] | undefined;
        if (currentUploadedImages.length === 2) {
          const imageArray: string[] = [];
          if (image1FileId) imageArray.push(image1FileId);
          if (image2FileId) imageArray.push(image2FileId);
          imageParam = imageArray;
        } else if (currentUploadedImages.length === 1) {
          imageParam = image1FileId;
        }
        const workflowParams: CozeWorkflowParams = { prompt: currentConfig.prompt, width: Number(currentConfig.img_width), height: Number(currentConfig.image_height) };
        if (currentUploadedImages.length === 2) { workflowParams.image = imageParam as string[]; } else if (currentUploadedImages.length === 1) { workflowParams.image1 = imageParam as string; }

        const workflowResult = await runWorkflow(workflowParams);
        if (workflowResult) {
          const dataUrl = await urlToDataURL(workflowResult);
          const savedPath = await saveImageToOutputs(dataUrl, { ...currentConfig, base_model: currentModel, timestamp: new Date().toISOString() });
          const result: GenerationResult = { id: taskId, imageUrl: dataUrl, savedPath, config: { ...currentConfig, base_model: currentModel }, timestamp: new Date().toISOString() };
          setGenerationHistory(prev => prev.map(item => item.id === taskId ? result : item));
          toast({ title: "ç”ŸæˆæˆåŠŸ", description: "Seed 4.0 å›¾åƒå·²æˆåŠŸç”Ÿæˆï¼" });
        } else {
          throw new Error("æœªæ”¶åˆ°æœ‰æ•ˆå›¾ç‰‡æ•°æ®");
        }
      } else if (currentModel === "Workflow") {
        if (!currentWorkflowConfig) {
          toast({ title: "é”™è¯¯", description: "è¯·å…ˆé€‰æ‹©å·¥ä½œæµ", variant: "destructive" });
          setGenerationHistory(prev => prev.filter(item => item.id !== taskId));
          return;
        }
        const flattenInputs = (arr: IMultiValueInput[]) => {
          const list: { key: string; value: unknown; valueType?: string; title?: string }[] = [];
          arr.forEach(group => {
            group.inputs.forEach((input: IInputField) => {
              list.push({ key: input.key, value: input.value, valueType: input.valueType, title: input.title });
            });
          });
          return list;
        };
        const allInputs = [...flattenInputs(currentWorkflowConfig.viewComfyJSON.inputs), ...flattenInputs(currentWorkflowConfig.viewComfyJSON.advancedInputs)];
        const mappingConfig = currentWorkflowConfig.viewComfyJSON.mappingConfig as { components: UIComponent[] } | undefined;

        let mappedInputs: { key: string; value: unknown }[] = [];
        if (mappingConfig?.components?.length) {
          const paramMap = new Map<string, unknown>();
          mappingConfig.components.forEach((comp: UIComponent) => {
            if (!comp.properties?.paramName || !comp.mapping?.workflowPath) return;
            const key = comp.mapping.workflowPath.join("-");
            const pName = comp.properties.paramName;
            if (pName === 'prompt' && currentConfig.prompt) paramMap.set(key, currentConfig.prompt);
            else if (pName === 'width') paramMap.set(key, currentConfig.img_width);
            else if (pName === 'height') paramMap.set(key, currentConfig.image_height);
            else if (pName === 'batch_size') paramMap.set(key, currentConfig.gen_num);
            else if (pName === 'base_model') paramMap.set(key, currentConfig.base_model || selectedModel);
            else if (['lora', 'lora1', 'lora2', 'lora3'].includes(pName)) {
              let idx = 0; if (pName === 'lora2') idx = 1; else if (pName === 'lora3') idx = 2;
              if (selectedLoras.length > idx) {
                const lora = selectedLoras[idx];
                const last = comp.mapping.workflowPath[comp.mapping.workflowPath.length - 1];
                if (last === 'strength_model' || last === 'strength_clip' || typeof comp.properties.defaultValue === 'number') {
                  paramMap.set(key, lora.strength);
                } else {
                  paramMap.set(key, lora.model_name);
                }
              }
            }
          });
          mappedInputs = allInputs.map(item => ({ key: item.key, value: paramMap.has(item.key) ? paramMap.get(item.key) : item.value }));
        } else {
          mappedInputs = allInputs.map(item => {
            if ((item.valueType === "long-text" || /prompt|æ–‡æœ¬|æç¤º/i.test(item.title || "")) && currentConfig.prompt) return { key: item.key, value: currentConfig.prompt };
            if (/width/i.test(item.title || "")) return { key: item.key, value: currentConfig.img_width };
            if (/height/i.test(item.title || "")) return { key: item.key, value: currentConfig.image_height };
            if (/batch|æ•°é‡|batch_size/i.test(item.title || "")) return { key: item.key, value: currentConfig.gen_num };
            if (/model|æ¨¡å‹|path|unet/i.test(item.title || "") && !/lora/i.test(item.title || "")) return { key: item.key, value: currentConfig.base_model || selectedModel };
            if (selectedLoras.length > 0 && /lora/i.test(item.title || "")) {
              if (/strength|weight|å¼ºåº¦/i.test(item.title || "")) return { key: item.key, value: selectedLoras[0].strength };
              return { key: item.key, value: selectedLoras[0].model_name };
            }
            return { key: item.key, value: item.value };
          });
        }

        await runComfyWorkflow({
          viewComfy: { inputs: mappedInputs, textOutputEnabled: false },
          workflow: currentWorkflowConfig.workflowApiJSON || undefined,
          viewcomfyEndpoint: currentWorkflowConfig.viewComfyJSON.viewcomfyEndpoint || null,
          onSuccess: async (outputs) => {
            if (outputs.length > 0) {
              const dUrl = await blobToDataURL(outputs[0]);
              const sPath = await saveImageToOutputs(dUrl, { ...currentConfig, base_model: currentModel, workflow: currentWorkflowConfig.viewComfyJSON.title });
              const result: GenerationResult = { id: taskId, imageUrl: dUrl, savedPath: sPath, config: { ...currentConfig, base_model: currentModel }, timestamp: new Date().toISOString() };
              setGenerationHistory(prev => prev.map(item => item.id === taskId ? result : item));
            } else {
              setGenerationHistory(prev => prev.filter(item => item.id !== taskId));
            }
          },
          onError: (error) => {
            setGenerationHistory(prev => prev.filter(item => item.id !== taskId));
            toast({ title: "ç”Ÿæˆå¤±è´¥", description: error?.errorMsg || error?.message || "å·¥ä½œæµæ‰§è¡Œå¤±è´¥", variant: "destructive" });
          }
        });
      } else {
        // é»˜è®¤ä½¿ç”¨ ByteArtist æ¥å£ (Lemo 2D/3D ç­‰)
        const response: ByteArtistResponse = await fetchByteArtistImage({
          conf: {
            width: currentConfig.img_width,
            height: currentConfig.image_height,
            batch_size: currentConfig.gen_num,
            seed: Math.floor(Math.random() * 2147483647),
            prompt: currentConfig.prompt
          },
          algorithms: algorithm,
          img_return_format: imageFormat
        });

        interface ByteArtistAFRItem { pic: string;[key: string]: unknown; }
        const afr = (response as { data?: { afr_data?: ByteArtistAFRItem[] } }).data?.afr_data;
        if (!afr?.[0]?.pic) throw new Error("æœªæ”¶åˆ°æœ‰æ•ˆå›¾ç‰‡æ•°æ®");

        const dataUrl = afr[0].pic.startsWith("data:") ? afr[0].pic : `data:image/${imageFormat};base64,${afr[0].pic}`;
        const savedPath = await saveImageToOutputs(dataUrl, { ...currentConfig, base_model: currentModel });
        const result: GenerationResult = {
          id: taskId,
          imageUrl: dataUrl,
          savedPath,
          config: { ...currentConfig, base_model: currentModel },
          timestamp: new Date().toISOString()
        };
        setGenerationHistory(prev => prev.map(item => item.id === taskId ? result : item));
        toast({ title: "ç”ŸæˆæˆåŠŸ", description: "å›¾åƒå·²æˆåŠŸç”Ÿæˆï¼" });
      }
    } catch (error) {
      console.error("ğŸ’¥ èƒŒæ™¯ç”Ÿæˆå¤±è´¥:", error);
      setGenerationHistory(prev => prev.filter(item => item.id !== taskId));
      toast({ title: "ç”Ÿæˆå¤±è´¥", description: error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯", variant: "destructive" });
    }
  };

  const handleRegenerate = async (resultConfig: GenerationConfig) => {
    updateConfig(resultConfig);
    // ç­‰å¾…çŠ¶æ€åŒæ­¥ï¼ˆè™½ç„¶ zustand æ˜¯åŒæ­¥çš„ï¼Œä½†ä¸ºäº†é€»è¾‘æ¸…æ™°ï¼‰
    setTimeout(() => {
      handleGenerate();
    }, 0);
  };

  const handleDownload = (imageUrl: string) => { const link = document.createElement("a"); link.href = imageUrl; link.download = `PlaygroundV2-${Date.now()}.png`; document.body.appendChild(link); link.click(); document.body.removeChild(link); };

  const openImageModal = (result: GenerationResult) => { setSelectedResult(result); setIsImageModalOpen(true); };
  const closeImageModal = () => {
    setIsImageModalOpen(false);
    // Don't clear selectedResult here to allow exit animation to use the data
  };

  const handleEditImage = (result: GenerationResult) => {
    const url = result.imageUrl || (result.imageUrls && result.imageUrls[0]) || "";
    if (url) {
      setEditingImageUrl(url);
      setIsEditorOpen(true);
      setIsImageModalOpen(false);
    }
  };

  const handleSaveEditedImage = async (dataUrl: string) => {
    setIsEditorOpen(false);
    try {
      // 1. Convert dataUrl to Blob
      const res = await fetch(dataUrl);
      const blob = await res.blob();
      const file = new File([blob], `edited-${Date.now()}.png`, { type: 'image/png' });

      // 2. Upload to server to get a path (consistent with standard upload flow)
      const form = new FormData();
      form.append('file', file);
      const uploadResp = await fetch('/api/upload', { method: 'POST', body: form });
      const uploadJson = await uploadResp.json();
      const path = uploadResp.ok && uploadJson?.path ? String(uploadJson.path) : undefined;

      // 3. Add to playground state
      const base64Data = dataUrl.split(',')[1];
      setUploadedImages(prev => [
        ...prev,
        { file, base64: base64Data, previewUrl: dataUrl, path }
      ]);

      toast({ title: "Image Saved", description: "The edited image has been added to your uploads." });
    } catch (error) {
      console.error("Failed to save edited image:", error);
      toast({ title: "Error", description: "Failed to save edited image", variant: "destructive" });
    }
  };


  // æ ·å¼å®šä¹‰

  const Inputbg = "relative z-10 flex items-center justify-center w-full text-black flex-col rounded-[30px] bg-black/50  backdrop-blur-xl border border-white/20 p-2 mx-auto";

  const renderThumbnails = () => {
    const showUploadButton = isInputHovered || uploadedImages.length > 0;
    if (uploadedImages.length === 0 && !showUploadButton) return null;

    return (
      <div className="absolute -top-16 left-10 flex gap-1 z-0 pointer-events-none">
        <AnimatePresence>
          {uploadedImages.map((image, index) => {
            const rotations = [-8, 6, -4, 5, -3];
            const rotation = rotations[index % rotations.length];
            return (
              <motion.div
                key={index}
                initial={{ y: 20, rotate: rotation }}
                animate={{ y: 0, rotate: rotation }}
                exit={{ y: 20, rotate: rotation }}
                transition={{ duration: 0.1, ease: "easeOut" }}
                className="relative group pointer-events-auto hover:z-50 p-1 -m-1"
              >
                <div className="relative p-2 transition-all duration-100 group-hover:-translate-y-5 group-hover:scale-110">
                  <Image
                    src={image.previewUrl}
                    alt={`ä¸Šä¼ çš„å›¾ç‰‡ ${index + 1}`}
                    width={80}
                    height={80}
                    className="w-20 h-20 object-cover rounded-2xl border-2 border-white/60 bg-black shadow-xl transition-all duration-300 group-hover:border-white group-hover:shadow-2xl"
                  />
                  <button
                    onClick={() => removeImage(index)}
                    className="absolute top-1 right-1 bg-black/60 backdrop-blur-md text-white border border-white/20 rounded-full w-6 h-6 flex items-center justify-center text-xs opacity-0 group-hover:opacity-100 transition-all duration-200 hover:bg-black hover:scale-110 z-10"
                  >
                    <X className="w-4 h-4" />
                  </button>
                </div>
              </motion.div>
            );
          })}

          {showUploadButton && (
            <motion.div
              key="upload-button"
              initial={{ y: 20, rotate: ([-8, 6, -4, 5, -3][uploadedImages.length % 5]) }}
              animate={{ y: 0, rotate: ([-8, 6, -4, 5, -3][uploadedImages.length % 5]) }}
              exit={{ scale: 0.8 }}
              transition={{ duration: 0.1, ease: "easeOut" }}
              className="relative group pointer-events-auto hover:z-50"
            >
              <div className="relative transition-all duration-300 group-hover:-translate-y-5 group-hover:scale-110">
                <button
                  onClick={() => fileInputRef.current?.click()}
                  className="w-20 h-20 flex items-center justify-center rounded-2xl border-2 border-dashed border-white/40 bg-white/5 backdrop-blur-md shadow-xl transition-all duration-300 hover:border-white/80 hover:bg-white/10 group-hover:shadow-2xl"
                >
                  <Plus className="w-8 h-8 text-white/40 group-hover:text-white/80 transition-colors" />
                </button>
              </div>
            </motion.div>
          )}
        </AnimatePresence>
      </div>
    );
  };


  return (
    <main className="relative h-screen flex flex-col bg-transparent overflow-hidden">
      {/* æ ¸å¿ƒå†å²ä¸é¢„è§ˆåŒºåŸŸ - åœ¨è¾“å…¥åŒºåŸŸä¸‹æ–¹ï¼ˆæˆ–èƒŒæ™¯ä¸­ï¼‰ */}
      <div className="flex-1 overflow-hidden relative z-0">
        <HistoryList
          history={generationHistory}
          onRegenerate={handleRegenerate}
          onDownload={handleDownload}
          onImageClick={openImageModal}
        />
      </div>

      {/* åŠ¨æ€è¾“å…¥åŒºåŸŸ - åˆå§‹å±…ä¸­ï¼Œç”Ÿæˆåå›ºå®šåœ¨åº•éƒ¨ */}
      <div className={cn(
        "w-full transition-all duration-700 ease-in-out z-50",
        hasGenerated
          ? "fixed top-0 left-0 right-0 pt-10  pb-8 px-4 "
          : "absolute inset-0 flex flex-col items-center justify-center pointer-events-none"
      )}>
        <div className={cn(
          "flex flex-col items-center  w-full transition-all duration-500 ease-in-out px-4 pointer-events-auto",
          hasGenerated ? "max-w-[50vw]  mx-auto mt-20" : "max-w-4xl"
        )}>


          <h1
            className={cn(
              "text-[40px] text-white text-center transition-all duration-500 overflow-hidden",
              hasGenerated ? "h-0 opacity-0 mb-0" : "h-auto opacity-100 mb-4"
            )}
          >
            Let Your Imagination Soar
          </h1>
          <div
            className={cn(
              "relative w-full rounded-[10px] transition-all duration-300",
              isInputHovered ? "mt-0" : "mt-0"
            )}
            onMouseEnter={() => setIsInputHovered(true)}
            onMouseLeave={() => setIsInputHovered(false)}
          >
            <input
              type="file"
              ref={fileInputRef}
              className="hidden"
              accept="image/*"
              multiple
              onChange={handleImageUpload}
            />
            {renderThumbnails()}

            <div className={Inputbg}>
              <div className="flex items-start gap-4 w-full">
                <PromptInput
                  prompt={config.prompt}
                  onPromptChange={(val) => setConfig(prev => ({ ...prev, prompt: val }))}
                  uploadedImages={uploadedImages}
                  onRemoveImage={removeImage}
                  isOptimizing={isOptimizing}
                  onOptimize={handleOptimizePrompt}
                  selectedAIModel={selectedAIModel}
                  onAIModelChange={setSelectedAIModel}
                  onAddImages={handleFilesUpload}
                />
              </div>
              <ControlToolbar
                selectedModel={selectedModel}
                onModelChange={setSelectedModel}
                config={config}
                onConfigChange={(newConf) => setConfig(prev => ({ ...prev, ...newConf }))}
                onWidthChange={handleWidthChange}
                onHeightChange={handleHeightChange}
                aspectRatioPresets={aspectRatioPresets}
                currentAspectRatio={getCurrentAspectRatio()}
                onAspectRatioChange={(ar: string) => {
                  const size = (config.base_model === 'Nano banana') ? (config.image_size || '1K') : '1K';
                  const resolution = AR_MAP[ar]?.[size] || AR_MAP[ar]?.['1K'];
                  if (resolution) {
                    setConfig(prev => ({ ...prev, img_width: resolution.w, image_height: resolution.h }));
                  }
                }}
                currentImageSize={(config.image_size as '1K' | '2K' | '4K') || '1K'}
                onImageSizeChange={(size: '1K' | '2K' | '4K') => {
                  const ar = getCurrentAspectRatio();
                  const resolution = AR_MAP[ar]?.[size];
                  if (resolution) {
                    setConfig(prev => ({ ...prev, image_size: size, img_width: resolution.w, image_height: resolution.h }));
                  }
                }}
                isAspectRatioLocked={isAspectRatioLocked}
                onToggleAspectRatioLock={() => setIsAspectRatioLocked(!isAspectRatioLocked)}
                onImageUpload={handleImageUpload}
                onGenerate={handleGenerate}
                isGenerating={isLoading}
                uploadedImagesCount={uploadedImages.length}
                loadingText={selectedModel === "Seed 4.0" ? "Seed 4.0 ç”Ÿæˆä¸­..." : "ç”Ÿæˆä¸­..."}
                onOpenWorkflowSelector={() => setIsWorkflowDialogOpen(true)}
                onOpenBaseModelSelector={() => setIsBaseModelDialogOpen(true)}
                onOpenLoraSelector={() => setIsLoraDialogOpen(true)}
                selectedWorkflowName={selectedWorkflowConfig?.viewComfyJSON.title}
                selectedBaseModelName={config.base_model}
                selectedLoraNames={selectedLoras.map(l => l.model_name)}
                workflows={workflows}
                onWorkflowSelect={(wf) => { setSelectedModel("Workflow"); setSelectedWorkflowConfig(wf); applyWorkflowDefaults(wf); }}
                onOptimize={handleOptimizePrompt}
                isOptimizing={isOptimizing}
                isMockMode={isMockMode}
                onMockModeChange={setIsMockMode}
                isSelectorExpanded={isSelectorExpanded}
                onSelectorExpandedChange={setIsSelectorExpanded}
              />
            </div>
          </div>
          <GoogleApiStatus className="fixed bottom-4 right-4" />
        </div>
      </div>

      <div className="absolute top-0 left-0 right-0 pt-24 z-80">
        <ImagePreviewModal
          isOpen={isImageModalOpen}
          onClose={closeImageModal}
          result={selectedResult}
          onEdit={handleEditImage}
        />

        <ImageEditorModal
          isOpen={isEditorOpen}
          imageUrl={editingImageUrl}
          onClose={() => setIsEditorOpen(false)}
          onSave={handleSaveEditedImage}
        />

      </div>


      <WorkflowSelectorDialog open={isWorkflowDialogOpen} onOpenChange={setIsWorkflowDialogOpen} onSelect={(wf) => setSelectedWorkflowConfig(wf)} onEdit={onEditMapping} />
      <BaseModelSelectorDialog open={isBaseModelDialogOpen} onOpenChange={setIsBaseModelDialogOpen} value={config.base_model || selectedModel} onConfirm={(m) => updateConfig({ base_model: m })} />
      <LoraSelectorDialog open={isLoraDialogOpen} onOpenChange={setIsLoraDialogOpen} value={selectedLoras} onConfirm={(list) => setSelectedLoras(list)} />
    </main>
  );
}


export default function PlaygroundV2Route() {
  return <PlaygroundV2Page />;
}
